{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Naive Bayes Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv8KLayBz6Py"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import random\n",
        "from itertools import chain\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "import os\n",
        "from chart_studio.plotly import plot, iplot\n",
        "from time import time"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAj7cY4OJKxl",
        "outputId": "a30a94f3-e3bd-4a2e-8290-6f62b3bb3428"
      },
      "source": [
        "pip install chart_studio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting chart_studio\n",
            "  Downloading chart_studio-1.1.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from chart_studio) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from chart_studio) (4.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from chart_studio) (2.23.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from chart_studio) (1.3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->chart_studio) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->chart_studio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->chart_studio) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->chart_studio) (2.10)\n",
            "Installing collected packages: chart-studio\n",
            "Successfully installed chart-studio-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LluEvhJqHFpv"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvv4inFInp3f"
      },
      "source": [
        "class Utility:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.train = np.asarray([np.reshape(x, (784)) for x in X_train]).astype('float64') \n",
        "        self.train_label = np.asarray(Y_train)\n",
        "        self.test = np.asarray([np.reshape(x, (784)) for x in X_test]).astype('float64') \n",
        "        self.test_label = np.asarray(Y_test)\n",
        "        self.n_class = list(range(10))\n",
        "        \n",
        "    def confusionMatrix(self, actual, predict, print_cfm=True, print_err_digit=True):\n",
        "        cfm = pd.DataFrame(confusion_matrix(actual, predict))\n",
        "        err_all = round((1 - sum(np.diagonal(cfm)) / len(predict)) * 100, 4)\n",
        "        error_digit = []\n",
        "        for i in self.n_class:\n",
        "            error_digit.append(round(1 - cfm.iloc[i,i] / sum(cfm.iloc[i,:]), 4) * 100)\n",
        "\n",
        "        tab_error = pd.DataFrame(columns=['digit', 'error per digit in %'])\n",
        "        tab_error['digit'] = self.n_class\n",
        "        tab_error['error per digit in %'] = error_digit\n",
        "\n",
        "        if print_cfm:\n",
        "            print('Testing Confusion Matrix: Actual vs. Prediction')\n",
        "            display(cfm)\n",
        "\n",
        "        if print_err_digit:\n",
        "            print('% error per digit')\n",
        "            display(tab_error)\n",
        "            print('\\nThe overall testing error is {}%'.format(err_all))\n",
        "\n",
        "        return cfm, tab_error, err_all\n",
        "\n",
        "\n",
        "    def nFoldCV_NB(self, train, train_label, smoothings, kFolds):\n",
        "        stra_all = self.folds_stratify(nSample=len(train), kFolds=kFolds)\n",
        "        ave_test_err = []\n",
        "        for s, sVal in enumerate(smoothings):\n",
        "            test_err = []\n",
        "            for k in range(kFolds):\n",
        "                stra = stra_all.copy()\n",
        "                te = train[stra[k]]\n",
        "                te_lb = train_label[stra[k]]\n",
        "                del stra[k]  # del test list\n",
        "                tr = train[list(chain.from_iterable(stra))]\n",
        "                tr_lb = train_label[list(chain.from_iterable(stra))]\n",
        "                nb = NaiveBayes(train=tr, train_lb=tr_lb, test=te, test_lb=te_lb, smoothing=sVal)\n",
        "                nb.predict()\n",
        "                conf = self.confusionMatrix(te_lb, nb.pred, False, False)\n",
        "                test_err.append(conf[2])\n",
        "\n",
        "            ave_test_err.append(np.mean(test_err))\n",
        "\n",
        "        return ave_test_err\n",
        "\n",
        "    def folds_stratify(self, nSample, kFolds):\n",
        "        foldSize = round(nSample / kFolds, 0)\n",
        "        randomList = list(range(0, nSample))\n",
        "        random.shuffle(randomList)\n",
        "        stratify = []\n",
        "\n",
        "        for k in range(0, kFolds):\n",
        "            strt = int(k * foldSize)\n",
        "            end = int((k + 1) * foldSize)\n",
        "            if k == (kFolds - 1):\n",
        "                end = nSample\n",
        "            stratify.append(list(randomList)[strt:end])\n",
        "\n",
        "        return stratify\n",
        "    \n",
        "    def CV_plot(k_error, k_list, title):\n",
        "        k_error = np.round(k_error, 4)\n",
        "        best_k = k_list[np.argmin(k_error)]\n",
        "        err_best_k = np.min(k_error)\n",
        "        plt.plot(k_list, k_error, '-gD', color='black')\n",
        "        ax = subplot(111)\n",
        "        ax.set_xticks(k_list, k_list)\n",
        "        plt.ylabel('% Error')\n",
        "        plt.xlabel(title)\n",
        "        plt.title('Plot of ' + title + ' vs. average 5 foldCV error')\n",
        "        plt.show()\n",
        "        print('The best value of ' + title + ' is {} with an error of {}%'.format(best_k, err_best_k))\n",
        "        print('\\n' + title + ' = {} will be used to model the entire training set and prediction on testing set:'.format(best_k))\n",
        "        return best_k, err_best_k\n",
        "        \n",
        "    def images_plot(imageData):\n",
        "        classes = [\"P(x|c=0)\", \"P(x|c=1)\", \"P(x|c=2)\", \"P(x|c=3)\", \"P(x|c=4)\", \"P(x|c=5)\", \"P(x|c=6)\", \"P(x|c=7)\",\n",
        "                   \"P(x|c=8)\", \"P(x|c=9)\"]\n",
        "\n",
        "        num_classes = len(classes)\n",
        "        plt.subplots(figsize=(15, 2))\n",
        "        for y, cls in enumerate(classes):\n",
        "            plt_idx = y + 1\n",
        "            plt.subplot(1, num_classes, plt_idx)\n",
        "            if prob:\n",
        "                plt.imshow(imageData[y].reshape((28, 28)))\n",
        "            else:\n",
        "                plt.imshow(imageData[y].reshape(785, 1)[1:785].reshape((28, 28)))\n",
        "            plt.axis(\"off\")\n",
        "            plt.title(cls)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "#End of Class Utility\n",
        "\n",
        "class NaiveBayes:\n",
        "    def __init__(self, train, train_lb, test, test_lb, smoothing, jupyter=True, plot_dis=False):\n",
        "        self.n_class = np.unique(train_lb)\n",
        "        self.tr = train\n",
        "        self.te = test\n",
        "        self.tr_lb = train_lb\n",
        "        self.te_lb = test_lb\n",
        "        self.plot_dis = plot_dis\n",
        "        self.jupyter = jupyter\n",
        "        self.smoothing = smoothing\n",
        "        if jupyter:\n",
        "            self.plotly = iplot\n",
        "        else:\n",
        "            self.plotly = plot\n",
        "\n",
        "    def mean_std_prior(self):\n",
        "        self.mean, self.std, self.priors, self.count = [], [], [], []\n",
        "        for i, val in enumerate(self.n_class):\n",
        "            sep = [self.tr_lb == val] #separated\n",
        "            self.count.append(len(self.tr_lb[sep]))\n",
        "            self.priors.append(len(self.tr_lb[sep]) / len(self.tr_lb))\n",
        "            self.mean.append(np.mean(self.tr[sep], axis=0))\n",
        "            self.std.append(np.std(self.tr[sep], axis=0))\n",
        "\n",
        "        if self.plot_dis:\n",
        "            bar_data = Bar(x=list(range(len(self.count))), y=self.count)\n",
        "            data_plt = Data([bar_data])\n",
        "            layout = Layout(yaxis=YAxis(title='counts'), xaxis=XAxis(title='classes', dtick=1),\n",
        "                            title='Class distribution in Train set')\n",
        "            fig = Figure(data=data_plt, layout=layout)\n",
        "            self.plotly(fig)\n",
        "\n",
        "    def predict(self):\n",
        "        str_time = time()\n",
        "        self.mean_std_prior()\n",
        "        self.pred = []\n",
        "        self.likelihood = []\n",
        "        self.logsum_chk = []\n",
        "        for n in range(len(self.te_lb)):\n",
        "            classifier = []\n",
        "            sample = self.te[n] #test sample\n",
        "            likelih = []\n",
        "            for i, val in enumerate(self.n_class):\n",
        "                mean = self.mean[i]\n",
        "                var = np.square(self.std[i]) + self.smoothing\n",
        "                prob = 1 / np.sqrt(2 * np.pi * var) * np.exp(-np.square(sample - mean)/(2 * var))\n",
        "                result = np.sum(np.log(prob)) #, np.log(self.priors[i])) #not needed, we assume equal prior\n",
        "                classifier.append(result)\n",
        "                likelih.append(prob)\n",
        "\n",
        "            self.pred.append(np.argmax(classifier))\n",
        "            self.likelihood.append(likelih)\n",
        "            self.logsum_chk.append(classifier)\n",
        "\n",
        "        self.end_time = time() - str_time\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNFdWMDWuNvz",
        "outputId": "18049a04-efd6-4062-abfd-244ce64337c4"
      },
      "source": [
        "util = Utility()\n",
        "smoothings_nb = list(range(500, 2100, 100))\n",
        "kfold_nb = util.nFoldCV_NB(util.train, util.train_label, smoothings_nb, kFolds=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:125: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:126: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:127: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVkZC81r871-"
      },
      "source": [
        "sm_plot = Utility.CV_plot(kfold_nb, smoothings_nb, 'smoothing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmyrkndLEgsM"
      },
      "source": [
        "\n",
        "util = Utility()\n",
        "best_s = smoothings_nb[np.argmin(kfold_nb)]\n",
        "nb = NaiveBayes(train=util.train, train_lb=util.train_label, test=util.test, test_lb=util.test_label, smoothing=best_s)\n",
        "nb.predict()\n",
        "conf_matix = util.confusionMatrix(util.test_label, nb.pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY0RxjOWEkWn"
      },
      "source": [
        "\n",
        "Utility.images_plot(nb.likelihood[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuAxuI9oEmxU"
      },
      "source": [
        "Utility.images_plot(nb.likelihood[9997])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}